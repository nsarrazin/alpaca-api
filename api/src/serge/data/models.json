[
    {   
        "name": "Starling",
        "models": [
            {
                "name": "Starling-LM-7B-Alpha",
                "repo": "TheBloke/Starling-LM-7B-alpha-GGUF",
                "files": [
                    {
                        "name": "q4_K_M",
                        "filename": "starling-lm-7b-alpha.Q4_K_M.gguf",
                        "disk_space": 4370000000.0
                    }
                ]
            }
        ]
    },    
    {   
        "name": "Neural-Chat",
        "models": [
            {
                "name": "Neural-Chat-7B-v3-1",
                "repo": "TheBloke/neural-chat-7B-v3-1-GGUF",
                "files": [
                    {
                        "name": "q4_K_M",
                        "filename": "neural-chat-7b-v3-1.Q4_K_M.gguf",
                        "disk_space": 4370000000.0
                    }
                ]
            }
        ]
    },
    {   
        "name": "OpenChat",
        "models": [
            {
                "name": "OpenChat-3_5-7B",
                "repo": "TheBloke/openchat_3.5-GGUF",
                "files": [
                    {
                        "name": "q4_K_M",
                        "filename": "openchat_3.5.Q4_K_M.gguf",
                        "disk_space": 4370000000.0
                    }
                ]
            }
        ]
    },            
    {
        "name": "Open_LLaMA",
        "models": [
            {
                "name": "Open_LLaMA-3B-v2",
                "repo": "maddes8cht/openlm-research-open_llama_3b_v2-gguf",
                "files": [
                    {
                        "name": "q4_K_M",
                        "filename": "openlm-research-open_llama_3b_v2-Q4_K_M.gguf",
                        "disk_space": 2580000000.0
                    }
                ]
            },
            {
                "name": "Open_LLaMA-7B-v2",
                "repo": "maddes8cht/openlm-research-open_llama_7b_v2-gguf",
                "files": [
                    {
                        "name": "q4_K_M",
                        "filename": "openlm-research-open_llama_7b_v2-Q4_K_M.gguf",
                        "disk_space": 4080000000.0
                    }
                ]
            },
            {
                "name": "Open_LLaMA-13B-V2",
                "repo": "maddes8cht/openlm-research-open_llama_13b-gguf",
                "files": [
                    {
                        "name": "q4_K_M",
                        "filename": "openlm-research-open_llama_13b-Q4_K_M.gguf",
                        "disk_space": 7870000000.0
                    }
                ]
            }            
        ]
    },
    {
        "name": "Orca-2",
        "models": [
            {
                "name": "Orca-2-7B",
                "repo": "TheBloke/Orca-2-7B-GGUF",
                "files": [
                    {
                        "name": "q4_K_M",
                        "filename": "orca-2-7b.Q4_K_M.gguf",
                        "disk_space": 4080000000.0
                    }
                ]
            },            
            {
                "name": "Orca-2-13B",
                "repo": "TheBloke/Orca-2-13B-GGUF",
                "files": [
                    {
                        "name": "q4_K_M",
                        "filename": "orca-2-13b.Q4_K_M.gguf",
                        "disk_space": 7870000000.0
                    }
                ]
            }
        ]
    },    
    {
        "name": "Meditron",
        "models": [
            {
                "name": "Meditron-7B",
                "repo": "TheBloke/meditron-7B-GGUF",
                "files": [
                    {
                        "name": "q4_K_M",
                        "filename": "meditron-7b.Q4_K_M.gguf",
                        "disk_space": 4080000000.0
                    }
                ]
            },            
            {
                "name": "Meditron-70B",
                "repo": "TheBloke/meditron-70B-GGUF",
                "files": [
                    {
                        "name": "q4_K_M",
                        "filename": "meditron-70b.Q4_K_M.gguf",
                        "disk_space": 41400000000.0
                    }
                ]
            }
        ]
    },    
    {
        "name": "Falcon",
        "models": [   
            {
                "name": "Falcon-40b",
                "repo": "maddes8cht/tiiuae-falcon-40b-gguf",
                "files": [
                    {
                        "name": "q4_K_M",
                        "filename": "tiiuae-falcon-40b-Q4_K_M.gguf",
                        "disk_space": 25500000000.0
                    }
                ]
            },
            {
                "name": "Falcon-40b-instruct",
                "repo": "maddes8cht/tiiuae-falcon-40b-instruct-gguf",
                "files": [
                    {
                        "name": "q4_K_M",
                        "filename": "tiiuae-falcon-40b-instruct-Q4_K_M.gguf",
                        "disk_space": 25500000000.0
                    }
                ]
            },
            {
                "name": "Falcon-7b",
                "repo": "maddes8cht/tiiuae-falcon-7b-gguf",
                "files": [
                    {
                        "name": "q4_K_M",
                        "filename": "tiiuae-falcon-7b-Q4_K_M.gguf",
                        "disk_space": 4980000000.0
                    }
                ]
            },
            {
                "name": "Falcon-7b-instruct",
                "repo": "maddes8cht/tiiuae-falcon-7b-instruct-gguf",
                "files": [
                    {
                        "name": "q4_K_M",
                        "filename": "tiiuae-falcon-7b-instruct-Q4_K_M.gguf",
                        "disk_space": 4980000000.0
                    }
                ]
            }             
        ]
    },
    {
        "name": "Vicuna",
        "models": [
            {
                "name": "Vicuna-7B",
                "repo": "TheBloke/vicuna-7B-v1.5-GGUF",
                "files": [
                    {
                        "name": "q4_K_M",
                        "filename": "vicuna-7b-v1.5.Q4_K_M.gguf",
                        "disk_space": 4080000000.0
                    }
                ]
            },
            {
                "name": "Vicuna-13B",
                "repo": "TheBloke/vicuna-13B-v1.5-GGUF",
                "files": [
                    {
                        "name": "q4_K_M",
                        "filename": "vicuna-13b-v1.5.Q4_K_M.gguf",
                        "disk_space": 7870000000.0
                    }
                ]
            }
        ]
    },
    {
        "name": "CodeLLaMA",
        "models": [
            {
                "name": "CodeLlama-7B",
                "repo": "TheBloke/CodeLlama-7B-GGUF",
                "files": [
                    {
                        "name": "q4_K_M",
                        "filename": "codellama-7b.Q4_K_M.gguf",
                        "disk_space": 4080000000.0
                    }
                ]
            },
            {
                "name": "CodeLlama-7B-Instruct",
                "repo": "TheBloke/CodeLlama-7B-Instruct-GGUF",
                "files": [
                    {
                        "name": "q4_K_M",
                        "filename": "codellama-7b-instruct.Q4_K_M.gguf",
                        "disk_space": 4370000000.0
                    }
                ]
            },
            {
                "name": "CodeLlama-13B-Instruct",
                "repo": "TheBloke/CodeLlama-13B-Instruct-GGUF",
                "files": [
                    {
                        "name": "q4_K_M",
                        "filename": "codellama-13b-instruct.Q4_K_M.gguf",
                        "disk_space": 7870000000.0
                    }
                ]
            }
        ]
    },
    {
        "name": "Zephyr",
        "models": [
            {
                "name": "Zephyr-7B-Alpha",
                "repo": "TheBloke/zephyr-7B-alpha-GGUF",
                "files": [
                    {
                        "name": "q4_K_M",
                        "filename": "zephyr-7b-alpha.Q4_K_M.gguf",
                        "disk_space": 4370000000.0
                    }
                ]
            },
            {
                "name": "Zephyr-7B-Beta",
                "repo": "TheBloke/zephyr-7B-beta-GGUF",
                "files": [
                    {
                        "name": "q4_K_M",
                        "filename": "zephyr-7b-beta.Q4_K_M.gguf",
                        "disk_space": 4370000000.0
                    }
                ]
            }
        ]
    },
    {
        "name": "Mistral",
        "models": [
            {
                "name": "Mistral-7B-Instruct",
                "repo": "TheBloke/Mistral-7B-Instruct-v0.1-GGUF",
                "files": [
                    {
                        "name": "q4_K_M",
                        "filename": "mistral-7b-instruct-v0.1.Q4_K_M.gguf",
                        "disk_space": 4370000000.0
                    }
                ]
            },
            {
                "name": "Mistral-7B",
                "repo": "TheBloke/Mistral-7B-v0.1-GGUF",
                "files": [
                    {
                        "name": "q4_K_M",
                        "filename": "mistral-7b-v0.1.Q4_K_M.gguf",
                        "disk_space": 4370000000.0
                    }
                ]
            },
            {
                "name": "Mistral-7B-OpenOrca",
                "repo": "TheBloke/Mistral-7B-OpenOrca-GGUF",
                "files": [
                    {
                        "name": "q4_K_M",
                        "filename": "mistral-7b-openorca.Q4_K_M.gguf",
                        "disk_space": 4370000000.0
                    }
                ]
            }
        ]
    },
    {
        "name": "LLaMA",
        "models": [
            {
                "name": "LLaMA2-7B-Chat",
                "repo": "TheBloke/Llama-2-7B-Chat-GGUF",
                "files": [
                    {
                        "name": "q4_K_M",
                        "filename": "llama-2-7b-chat.Q4_K_M.gguf",
                        "disk_space": 4080000000.0
                    }
                ]
            },
            {
                "name": "LLaMA2-13B-Chat",
                "repo": "TheBloke/Llama-2-13B-chat-GGUF",
                "files": [
                    {
                        "name": "q4_K_M",
                        "filename": "llama-2-13b-chat.Q4_K_M.gguf",
                        "disk_space": 7870000000.0
                    }
                ]
            },
            {
                "name": "LLaMA2-70B-Chat",
                "repo": "TheBloke/Llama-2-70B-Chat-GGUF",
                "files": [
                    {
                        "name": "q4_K_M",
                        "filename": "llama-2-70b-chat.Q4_K_M.gguf",
                        "disk_space": 41420000000.0
                    }
                ]
            }
        ]
    }
]
